% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

\documentclass[12pt]{article} 

\usepackage[utf8]{inputenc} 


%%% PAGE DIMENSIONS
\usepackage[margin=3.3cm]{geometry} 
\geometry{a4paper} 
\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{graphicx} % support the \includegraphics command and options
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{mathtools}
\usepackage[hidelinks]{hyperref}
\usepackage{dirtytalk}
\usepackage[usenames, dvipsnames]{color}
\urlstyle{same}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{setspace}
\usepackage{eurosym}
\usepackage{listings} %% for R Code
\usepackage{nomencl}
\usepackage{bm}
\usepackage{fancyhdr}
\usepackage{rotating}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsfonts}
\usepackage{mathtools,bbm}%Use your favorite font for bboard number
%\usepackage[
%backend=biber,
%style=authoryear-icomp,
%citestyle=authoryear-icomp,
%maxcitenames=2
%]{biblatex}
%#\addbibresource{biblio.bib}

\usepackage{multirow}
\usepackage[dvipsnames]{xcolor}
\usepackage[toc,page]{appendix}
\usepackage{color, colortbl}
\definecolor{LightCyan}{HTML}{f2f2f2}
\usepackage{longtable}

\usepackage[round]{natbib}
\bibliographystyle{apa-good}
\renewcommand{\bibname}{References}


\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\newcommand{\blue}[1]{\textcolor{blue}{#1}}

% ------------------------------------------
% Tuning of the NOMENCLATURE!
%% This code creates the groups
% -----------------------------------------
\usepackage{etoolbox}
\renewcommand\nomgroup[1]{%
  \item[\bfseries
  \ifstrequal{#1}{A}{Sets \& Indices}{%
  \ifstrequal{#1}{B}{Distributions}{%
  \ifstrequal{#1}{C}{Variables \& Arrays}{%
  \ifstrequal{#1}{E}{Other Symbols}{%
  \ifstrequal{#1}{D}{Functions}{%
  \ifstrequal{#1}{F}{Acronyms}{}}}}}}%
]}


\renewcommand{\nomlabel}[1]{#1 \dotfill}

\renewcommand{\appendixname}{Appendix: Full Simulation Results}
\renewcommand{\appendixtocname}{Appendix: Full Simulation Results}
\renewcommand{\appendixpagename}{\Large Appendix: Full Simulation Results}

% -----------------------------------------
%%%%%%%%%%%
%%%%%%%%%%%

%%% Listings options
\lstdefinelanguage{Renhanced}[]{R}{
  otherkeywords={!,!=,~,\$,*,\&,\%/\%,\%*\%,\%\%,<-,<<-, ::},
  morekeywords={},
  deletekeywords={hist, runif, plot,  R, read.table, read, check, text, file, attributes, quote, missing, c, any, which, na, deparse, structure, install, page, model, par, data, round, D, system, terms},
  alsoletter={.\%},%
  alsoother={:_\$}}
 \lstset{ 
  language=Renhanced,                     % the language of the code
  basicstyle=\small\ttfamily, % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{Blue},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it is 1, each line will be numbered
  numbersep=10pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=false,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  keywordstyle=\color{RoyalBlue},      % keyword style
  commentstyle=\color{YellowGreen},   % comment style
  stringstyle=\color{ForestGreen}      % string literal style
} 
%\renewcommand{\lstlistingname}{Code-Chunk}
%%% New commands
\newcommand{\li}{\lstinline}
%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}


%%%%----------- SECTION TITLE APPEARANCE -----------------------------
%%% 
%\usepackage{sectsty}
%\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)
%%% ToC (table of contents) APPEARANCE
% --------------------------------------------------------------------
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!
\usepackage{setspace}
\onehalfspacing
%%% END Article customizations

\renewcommand{\sectionmark}[1]{\markright{\ #1}}

%%% The "real" document content comes below...
\begin{document}
\newgeometry{margin=2.5cm}
%\begin{titlepage}
\thispagestyle{empty}
\newcommand{\HRule}{\rule{\linewidth}{0.6mm}} % Defines a new command for the horizontal lines, change thickness here
%\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

%\begin{spacing}{1.5}
%{\vspace{-4cm} \Large Flexible Instrumental Variables Distributional Regression:}\\[.35cm]
%{\Large A Simulation and Empirical Study}\\% Title of your document
%\end{spacing}
%\HRule \\[4cm]

%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------
%\textsc{Georg-August Universität G\"ottingen}\\[1.5cm] % Name of your university/college
%\textsc{Master of Science's Thesis}\\[0.5cm] % Major heading such as course name

%\text{\large Master Thesis presented to the Department of Economics at the}\\[.3cm]
%\text{\large Georg-August-University G\"ottingen} \\[.3cm]
%\text{\large with a working time of 20 weeks}\\[3cm]

%\text{\large In partial fulfillment of the requirements for the degree}\\[.3cm]
%\text{\large Master of Science (M.Sc.)}\\[4cm]

%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------
%\begin{minipage}{0.4\textwidth}
%\begin{flushleft} \large
%Author:\\
%Guillermo Briseño Sanchez\\
%Student ID: 21565589
%\end{flushleft}
%\end{minipage}
%~
%\begin{minipage}{0.4\textwidth}
%\begin{flushright} \large
%Supervisors: \\
%Prof. Dr. Thomas Kneib\\ % Supervisor's Name
%Maike Hohberg, M.A.
%\end{flushright}
%\end{minipage}\\[1cm]

%\text{\large Guillermo Briseño Sanchez}\\
%\text{from: Nuevo Laredo, Mexico}\\
%\text{(21565589)}\\[2cm]

%\text{Supervised by:}\\
%\text{Prof. Dr. Thomas Kneib}\\
%\text{Maike Hohberg, M.A.}\\[.7cm]

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------
%{Submitted: February 2, 2018}\\[3.2cm] % Date, change the \today to a set date if you want to be %precise
%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------
%\includegraphics{figures/logo}\\[1cm]
 
%----------------------------------------------------------------------------------------
%\vfill % Fill the rest of the page with whitespace
%\end{titlepage}
%\restoregeometry


\thispagestyle{empty}
\begin{center}
    \large
    \textbf{Instrumental Variable Distributional Regression with implicit variable selection via Boosting.}
    \vspace{0.03cm}
    
    \large    
    \vspace{0.03cm}
    %\textbf{Abstract}
\end{center}

%\textbf{Introduction:} Econometrical empirical research is subject to two main shortcomings: Not accounting for possible endogeneity, and assumption of a strictly linear covariate-response relationship. Without accounting for endogeneity, estimation of a covariate's effect on the response will be biased and inconsistent. Instrumental Variables (IV) methods are commonly employed to tackle this issue. Standard IV methods like Two-Stage Least Squares produce consistent estimates, but are limit the covariates to a strictly linear representation. The appropriate functional forms of the regressors are most certainly not known in advance and the response's dependence on the covariates might exhibit complex shapes. \\

%\textbf{Methods:} The IV approach embedded into the Distributional Regression framework. Two IV-DR methods are proposed: Two-Stage GAMLSS (2SGAMLSS), and Two-Stage Distributional Regression (2SDR). Both estimate the conditional response distribution parameters using a two-step procedure. 2SGAMLSS relies purely on two GAMLSS-type models, whereas 2SDR is a hybrid method that combines Expectile regression with GAMLSS. Empirical properties of IV-DR methods are investigated by means of a simulation study. Point-wise accuracy, and goodness-of-fit are evaluated using 1500 Monte Carlo replications. Subsequently, both methods are employed to estimate the relationship between education, and fertility using data from Botswana.\\

%\textbf{Results:} Overall IV-DR methods showed a superior point-wise accuracy, and consistent estimates of the endogenous regressor's effect on the response. IV-DR methods are favoured by multiple model selection criteria such as AIC, BIC, and Likelihood Ratio Tests. The empirical study showed that using IV-DR produces a different estimate of education's effect on fertility. Education has a negative effect on the log-odds of fertility being zero. Indicating that the mechanisms under which the education-fertility paradigm operates are more complex than expected. \\

%\textbf{Conclusion:} IV-DR methods can successfully correct the estimated effect of an endogenous regressor. The proposed approaches could be employed in research areas that rely heavily on observational data, such as health economics, ecology, and epidemiology.  
%\pagebreak


%\clearpage
%\tableofcontents
%\pagenumbering{Roman}
%\clearpage
%\listoffigures
%\listoftables
%\lstlistoflistings
%\clearpage
% NOMENCLATURE!!!!
%\makenomenclature
%\renewcommand{\nomname}{Nomenclature}
%\printnomenclature[.9in] 
%\clearpage



\pagenumbering{arabic}
%\pagestyle{fancy}
%\fancyhf{}
%\rhead{\nouppercase{\rightmark}}
%\lhead{G. Briseño}
%\rfoot{\thepage}
%\renewcommand{\headrulewidth}{1pt}
%\renewcommand{\footrulewidth}{1pt}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%             2   S   G   A   M   L   S   S
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Simulation settings}

\begin{equation*}
    x_{exo_1} \sim \mathcal{U}[0,1], \quad x_{exo_2} \sim \mathcal{U}[0,1], \quad   x_{exo_3} \sim \mathcal{U}[0,1], \quad x_{u} \sim \mathcal{U}[0,1], \quad  x_{IV} \sim \mathcal{U}[0,1] 
    \label{datageneration}
    \end{equation*}
Generate the additive predictor of endogenous regressor: 
    \begin{align*}
    \eta^{en} &= \phi_1 f_d(x_u) + \phi_2 f_d(x_{IV})
    \end{align*}
Obtain the location parameter of the endogenous regressor’s distribution by applying the inverse logit function to the additive predictor $\eta^{en}_{}$. Sample $N$ observations of $x_{en}$ from the desired distribution.
    \begin{align*}
    \vartheta^{en} &= g_1(\eta^{en})^{-1}  = \frac{\exp(\eta^{en})}{1+\exp(\eta^{en})}\\
    x_{en} &\sim Bin(1,\vartheta^{en}_{})
    \end{align*}
Using the sampled binary treatment $x_{en}$, generate the response $y$ from an arbitrary distribution by applying a non-linear function to the covariates, e.g.
    \begin{align*}
    \eta^{y}_{1} &= f_{d}(x_{exo1}) + f_{d}(x_{exo3}) + x_{en}\beta_{en} + f_d(x_u) \\
    \eta^{y}_{2} &= f_{d}(x_{exo2}) + f_{d}(x_{exo3}) +  x_{en}\gamma_{en} + f_d(x_u) 
    \end{align*}
    Obtain the response distribution parameters by applying a suitable response function to each additive predictor $\eta^{y}_{1}$ and $\eta^{y}_{2}$. Sample $N$ observations of $y$ from the desired conditional response distribution
    \begin{align*}
    \vartheta^{y}_{k} &= g_k(\eta^{y}_k)^{-1} \\
    y &\sim f_y(y|\vartheta^{y}_{1}, \dots, \vartheta^{y}_{K})
    \label{responsegeneration}
    \end{align*}
Where $f_d(\bigcdot)$ are some non-linear functions. The parameters $\phi_1, \phi_2$ are used to regulate the strength of the instrument: $\rho(f_d(x_{IV}), x_{en})$, and the severeness of the endogeneity: $\rho(x_{en},f_d(x_{u}))$.  

\underline{Distributional Combinations:}\\
Continuous instrument, binary endogenous treatment ($x_{en}\sim Bin(1, \vartheta^{en})$) with the following response distributions: Gaussian($\mu, \sigma$),  Logistic($\mu, \sigma$), Bernoulli($\mu$), Beta($\mu, \sigma$) [Might be relevant due to the bounded outcome in the application].

\underline{Estimation methods:}\\
The methods are denoted by the following suffix: 
\begin{itemize}
\item[${NBoost}$:] Noncyclic Boosting, non-optimal $mstop$. The first-stage runs until the user-specified $mstop$ is reached.
\item[${OptBoost}$:] Noncyclic Boosting, optimal $mstop$ via $k$-fold cross-validation ($k=10$).
\item[${Full}$:] Maximum Likelihood estimation via \texttt{GJRM} on the full set of covariates (including noise).
\item[${Sparse}$:] Maximum Likelihood estimation via \texttt{GJRM} on a subset of covariates after stability selection (\texttt{MB} original sampling type) based on an optimal $mstop$, i.e. $mstop_{OptBoost}$.
\end{itemize}
These methods yield: $\hat{\xi}_{i,NBoost}, \quad \hat{\xi}_{i,OptBoost}, \quad \hat{\xi}_{i,Full}, \quad \hat{\xi}_{i,Sparse}$.

\underline{Fitted equations:} \\
The first-stage (AKA \say{reduced form}) equation is the following: 
\begin{align*}
    \eta^{en}_{i} &= \alpha_0 + f(x_{i,IV}) + f(x_{i,exo1}) + f(x_{i,exo2}) + f(x_{i,exo3}) + \sum_{s = 1}^{10} f_s(x^{noise}_{i,s})
\end{align*}

Obtain the residuals $\hat{\xi}_{i,\bigcdot}$:
$$
\hat{\xi}_{i,\bigcdot} = x_{i,en} - \mathbb{E}(x_{i,en}|\hat{\vartheta}_{i,\bigcdot})
$$
where $\bigcdot$ denotes the estimation method.

In general, the second-stage model estimates the following equations: 
\begin{align*}
    \eta^{y}_{i,1} &= \beta_0 + x_{i,en}\beta_{en} + f(\hat{\xi}_{i,\bigcdot}) + f(x_{i,exo1}) + f(x_{i,exo2}) + f(x_{i,exo3}) + \sum_{s = 1}^{10} f_s(x^{noise}_{i,s}) \\
    \eta^{y}_{i,2} &= \gamma_0 + x_{i,en}\gamma_{en} + f(\hat{\xi}_{i,\bigcdot}) + f(x_{i,exo1}) + f(x_{i,exo2}) + f(x_{i,exo3}) + \sum_{s = 1}^{10} f_s(x^{noise}_{i,s}) \\
\end{align*}
e.g. $\eta^{y}_{i,1} = \mu_i$ and $\eta^{y}_{i,2} = \log(\sigma_i)$ in case of a Gaussian distributed response.

\underline{Strategies for second-stage equations:}
\begin{itemize}
\item[I:]{Fit a Maximum Likelihood GAMLSS using \texttt{GJRM::gamlss()} for each $\hat{\xi}_{\bigcdot}$ using only the signal covariates, no noise variables, no unobserved confounder.}
 \item[II:]{Fit the following combinations, including noise variables.
\begin{table}[h!]
\centering
\begin{tabular}{cl|cl}
\toprule
\rowcolor{LightCyan}
i & $\hat{\alpha}_{NBoost} \rightarrow \hat{\beta}_{NBoost}$ & vi & $\hat{\alpha}_{OptBoost} \rightarrow \hat{\beta}_{Sparse}$ \\
ii & $\hat{\alpha}_{NBoost} \rightarrow \hat{\beta}_{OptBoost}$ & vii & $\hat{\alpha}_{Sparse} \rightarrow \hat{\beta}_{NBoost}$  \\
\rowcolor{LightCyan}
iii & $\hat{\alpha}_{NBoost} \rightarrow \hat{\beta}_{Sparse}$  & viii & $\hat{\alpha}_{Sparse} \rightarrow \hat{\beta}_{OptBoost}$ \\
iv & $\hat{\alpha}_{OptBoost} \rightarrow \hat{\beta}_{NBoost}$  & ix &  $\hat{\alpha}_{Sparse} \rightarrow \hat{\beta}_{Sparse}$ \\
\rowcolor{LightCyan}
v & $\hat{\alpha}_{OptBoost} \rightarrow \hat{\beta}_{OptBoost}$  & x & $\hat{\alpha}_{Full} \rightarrow \hat{\beta}_{Full}$  \\
\bottomrule
\end{tabular}
\end{table} 
 
Here combination x is taken as the benchmark.
 }
\end{itemize}

\underline{Metrics:}
\begin{itemize}
\item{For first-stage equation: Absolute bias, MSE of the intrument’s effect on the treatment depending on $\hat{\alpha}_{\bigcdot}$.
\begin{align*}
AbsBias(\hat{f}(x_{IV, \bigcdot})) &= \frac{1}{N}\sum_{i=1}^N|f(x_{i,IV})-\hat{f}(x_{i,IV, \bigcdot})|\\
MSE(\hat{f}(x_{IV,\bigcdot})) &= \frac{1}{N}\sum_{i=1}^N(f(x_{i,IV})-\hat{f}(x_{i,IV, \bigcdot}))^2
\end{align*}
due to the instrument $x_{IV}$ having a non-linear effect on the endogenous treatment. The symbol $\bigcdot$ denotes the estimation method ($NBoost, OptBoost, Full, Sparse$). Relevant for strategy I \& II.
}
\item{MSE of prediction of the endogenous treatment.
$$
MSE(\hat{x}_{en, \bigcdot}) = \frac{1}{N}\sum_{i=1}^N(x_{i,en}-\hat{x}_{i,en,\bigcdot})^2
$$
where $\bigcdot$ denotes the estimation method ($NBoost, OptBoost, Full, Sparse$). Relevant for strategy I \& II.
}
\item{Bias and MSE of treatment effects $\hat{\beta}_{en,\bigcdot}, \hat{\gamma}_{en,\bigcdot}$
\begin{align*}
Bias(\hat{\beta}_{en,\bigcdot}) &= \frac{1}{C}\sum_{c=1}^C(1-\hat{\beta}_{c,en,\bigcdot})\\
MSE(\hat{\beta}_{en, \bigcdot}) &= \frac{1}{C}\sum_{c=1}^C(1-\hat{\beta}_{c,en,\bigcdot})^2
\end{align*}
where $c=1,\dots,C$ is the total amount of \say{Monte Carlo} replications (independent data-sets) and $\bigcdot$ denotes the estimation method ($NBoost, OptBoost, Full, Sparse$). Relevant for strategy I \& II.
}
\item Selection frequencies / \# of selected false positive covariates for boosting models. Relevant for strategy I \& II.
\item Convergence of $Full$ and $Sparse$ models.
\item Computation time. Relevant for strategy II.
\item Coverage probability of confidence intervals for treatment effects (only on FINAL strategy, TBD).
\end{itemize}

 
\blue{\underline{Status:}\\
Checking $C=200$ samples of the following combination: Binomial response, $N = 500$.
\begin{itemize}
\item $AbsBias$: $NBoost$ estimator appears to show the lowest values, followed by $OptBoost$ 
\item $Bias$: $Sparse$ estimator performs just as good as $Full$. Obvious advantage is the sparsity in the estimator.
\item $MSE(x_{IV})$: The $Sparse$ \& $OptBoost$ estimators outperform the $Full$ estimator. 
\item $MSE(x_{en})$: $OptBoost$ outperforms the other two (serious) estimators.
\end{itemize}
This leads me to believe / expect that the $OptBoost$ will generate the \say{best} residuals... but we'll see.
Should focus on the Logistic distributed response tho... 
}


\pagebreak



%
%\pagebreak
%The GAMLSS framework relaxes the distributional assumption, and allows the parameters of the conditional response distribution to be modelled as functions of the covariates \citep{rigby2005generalized}. Given a sample of observations from a response variable  $\boldsymbol{y} = (y_1, \dots, y_n)$, and a set of $J$ different covariates $\boldsymbol{x} = (x_1, \dots, x_J)$, the conditional response distribution is assumed to be from a class of $K$-parametric distributions: $y_i \sim f_{y}(y_i|\vartheta^{y}_{1},\dots, \vartheta^{y}_{K})$. All $K$ distribution parameters are modelled by using an additive predictor. These two components are then joined via a suitable link function $g_k(\bigcdot)$:
%\begin{equation}
%    \vartheta_k = g_k(\boldsymbol{\eta}_k)^{-1} = \boldsymbol{X}\boldsymbol{\beta} + f_{k,1}(x_{k,1}) + \dots + f_{k,J}(x_{J}) 
%\label{AdditivePredictor}
%\end{equation}
%The GAMLSS additive predictor consists of the parametric, and semi-parametric components. The former contains all discrete covariates in the data, such as treatment indicators, factors, as well as the intercept. The latter includes the possible non-linear effects of the continuous regressors.
%\par To achieve a reliable estimation of the parameters of interest, the Instrumental Variables method of Two-Stage GAMLSS (2SGAMLSS) is introduced. Emulating the mechanics of its predecessors, 2SGAMLSS performs a flexible location-based regression on the reduced form equation of the endogenous covariate:
%\begin{equation}
%\boldsymbol{\eta}^{en}_1 = \boldsymbol{\Tilde{X}}\boldsymbol{\delta}^{[1]} + f^{[1]}_{1}(x_{IV}) + f^{[1]}_2(x_{ex}) + \dots + f^{[1]}_R(x_R) 
%\label{firststageGAMLSS}
%\end{equation}
%Where $\eta^{en}_{1}$ is the additive predictor of the location parameter of the endogenous covariate, denoted by $\mu^{en}$. The superscript [1] indicates that the terms specified in \ref{firststageGAMLSS} belong to the first-stage model. The design matrix $\boldsymbol{\Tilde{X}}$ contains the observations of the discrete instrument, and exogenous regressors. The vector $\boldsymbol{\delta}$ denotes their respective first-stage regression coefficients. The functions $f(\bigcdot)$ represent effects of the continuous exogenous variables, and instruments. Equation \ref{firststageGAMLSS} implies that the first-stage regression is a typical mean regression as in 2SGAMLSS's predecessors. Although the type of distribution remains unrestricted, hence any implemented parametric distribution can be specified such that the estimation retains the high flexibility offered by the GAMLSS framework. After estimating the parameters of interest, the response residuals are computed: 
%\begin{equation*}
%    \boldsymbol{\hat{\xi}}_{en} = \boldsymbol{x}_{en} - \boldsymbol{\hat{x}}_{en}
%\end{equation*}
%In the second step, all $K$ parameters of $f_y(y|\bigcdot)$ are regressed on the covariates, and the response residuals:
%\begin{align}\label{seconds1}
%\vartheta_1^{y} &= \mu^y = g_1(\boldsymbol{\eta}_1)^{-1} = \boldsymbol{X}_{1}\boldsymbol{\beta}_{1}^{[2]} + f^{[2]}_{1,1}(x_{1,1}) + \dots + f^{[2]}_{1,J}(x_{1,J})\\
%\vartheta_2^{y} &=\sigma^y =  g_2(\boldsymbol{\eta}_2)^{-1} = \boldsymbol{X}_{2}\boldsymbol{\beta}_{2}^{[2]} + f^{[2]}_{2,1}(x_{2,1}) + \dots + f^{[2]}_{2,J}(x_{2,J})\\
%\vartheta_3^{y} &= \nu^y =  g_3(\boldsymbol{\eta}_3)^{-1} = \boldsymbol{X}_{3}\boldsymbol{\beta}_{3}^{[2]} + f^{[2]}_{3,1}(x_{3,1}) + \dots + f^{[2]}_{3,J}(x_{3,J})\\
%\vartheta_4^{y} &= \tau^y =g_4(\boldsymbol{\eta}_4)^{-1} = \boldsymbol{X}_{4}\boldsymbol{\beta}_{4}^{[2]} + f^{[2]}_{4,1}(x_{4,1}) + \dots + f^{[2]}_{4,J}(x_{4,J})
%\label{secondstageGAMLSS}
%\end{align}
%Where the superscript $[2]$ indicates that the components of the $K$ distribution parameters belong to the
%second-stage model. Equations \ref{seconds1}-\ref{secondstageGAMLSS} exemplify the typical four parameters of a GAMLSS model: Location ($\mu$), scale ($\sigma$), and shape ($\nu$, $\tau$).
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%         S   I   M   U   L   A   T   I   O   N
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%                     S   T   U   D   Y   
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%------------------------------------------------------------
%% S I M U L A T I O N    S T U D Y 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%------------------------------------------------------------
%\pagebreak
%\section*{Simulation Study}
%The point-wise precision of the new IV Distributional Regression (IV-DR) method in different configurations is investigated through a simulation study. The 2SGAMLSS is compared against a 2SLS, and a Benchmark model. This Section is comprised of the following: First, the blueprints of the data-generating process, and synthetic data generation algorithm are presented. Control, reproducibility, efficiency, as well as careful and complete documentation are key characteristics of this study. Therefore, common parameter settings are documented to allow for exact replication of the study's findings. Finally, the results are presented and discussed. All calculations are performed in \li{R} version 3.4.3 (2017-11-30) (Kite-Eating Tree) in Ubuntu 17.04 \citep{RTeam}. \\
%The \li{R} extensions 
%\begin{itemize}
%    \item \li{GJRM} \citep{gjrmgamlss}.
%    \item \li{AER} \citep{aer}
%    \item \li{scales} \citep{ScalesPack}.
%    \item \li{Metrics} \citep{MetricsPack}.
%    \item \li{ggplot2} \citep{ggplotPack}.
%    \item \li{xtable} \citep{xtablepack}.
%    \item \li{texreg} \citep{texreg}.
%\end{itemize}
%were employed for calculating the models, and displaying of the results. From here onward, the superscripts $en$, and $y$, denote the belonging of a parameter $(\vartheta^{en}, \vartheta^{y})$, predictor $(\eta^{en}, \eta^{y})$, and distribution $(f_{en}, f_{y})$, to the response, and endogenous variable, respectively. The observation index $i = 1, \dots, n$ dropped to reduce clutter. The entire \li{R} code, as well as the data sets containing the results are included in a digital supplement.
%\pagebreak
%\subsection{Design}
%The generation of synthetic data starts from a set of multiple additive predictors. Through the use of link functions, different regressors can be associated to the multiple parameters (location, scale, shape) of arbitrary distributions. The additive predictors are constructed in such fashion that the following properties are attained: (1) The relationship between the regressors and the response's predictor exhibits non-linear functional forms. (2) The regressor $x_{en}$ is endogenous due to correlation with an omitted variable $x_u$. (3) An instrument $x_{IV}$ induces \textit{sufficient} variation in $x_{en}$ and has no effect on the response $y$, after conditioning on $x_{en}$. (4) The instrument $x_{IV}$ is independent of the unmeasured confounder $x_u$. (5) The endogenous regressor $x_{en}$ affects the location, as well as other parameters of the response distribution. The predictors are generated using following procedure: \\
%Sample $N$ observations of the exogenous regressors, unobserved confounder, and the instrument from independent, univariate Uniform distributions
%\begin{equation}
%    x_{ex_1} \sim \mathcal{U}[0,1] \qquad x_{ex_2} \sim \mathcal{U}[0,1] \qquad \text{} \qquad x_{u} \sim \mathcal{U}[0,1] \qquad \text{} \qquad x_{IV} \sim \mathcal{U}[0,1] 
%    \label{datageneration}
%    \end{equation}
%Generate the endogenous regressor: 
%    \begin{align}
%    \eta^{en}_{1} &= \phi_1 f_d(x_u) + \phi_2 f_d(x_{IV})
%    \end{align}
%    Obtain the distribution parameter of the endogenous regressor’s distribution by applying the response function to the additive predictor. Sample $N$ observations of $x_{en}$ from the desired distribution
%    \begin{align}
%    \vartheta^{en}_{m} &= g_m(\eta^{en}_m)^{-1} \\
%    x_{en} &\sim f_{en}(x_{en}|\vartheta^{en}_{1})
%    \end{align}
%Using the sampled $x_{en}$, generate $y$ from an arbitrary distribution by applying a non-linear function to the covariates, e.g.
%    \begin{align}
%    \eta^{y}_{1} &= f_{d}(x_{ex}) + f_d(x_{en}) + f_d(x_u) \\
%    \eta^{y}_{2} &= f_d(x_{en}) + f_d(x_u) 
%    \end{align}
%    Obtain the response distribution parameters by applying the response function to each predictor. Sample $N$ observations of $y$ from the desired conditional response distribution
%    \begin{align}
%    \vartheta^{y}_{k} &= g_k(\eta^{y}_k)^{-1} \\
%    y &\sim f_y(y|\vartheta^{y}_{1}, \dots, \vartheta^{y}_{K})
%    \label{responsegeneration}
%    \end{align}
%Where $f_d(\bigcdot)$ are any of the non-linear functions shown in Table \ref{functions}. All functions $f_d(\bigcdot)$ are re-scaled to the domain $[0,1]$. Their forms are displayed in Figure \ref{FunctionsPlots}. The parameters $\phi_1, \phi_2$ are used to regulate the strength of the instrument: $\rho(f_d(x_{IV}), x_{en})$, and the severeness of the endogeneity: $\rho(f_d(x_{en}),f_d(x_{u}))$. $\eta^{en}_{}$ and $\eta^{y}_{}$ represent the respective fully additive predictors of the parameters of each variable. $g(\bigcdot)$ are the corresponding link functions, and $f_{\bigcdot}(\bigcdot|\vartheta^{\bigcdot}_{\bigcdot})$ denotes the conditional distribution functions of the endogenous and response variables. 
%%\begin{figure}[ht]
%%    \centering
%%    \includegraphics[scale = 0.39]{NLHorizontal.png}
%%    \caption{Plots of the functions shown in Table \ref{functions}.}
%%    \label{FunctionsPlots}
%%\end{figure}
%
%Additionally, an alternative Data Generating Process consisting of purely linear effects is considered. Instead of relying on the non-linear functions $f_d(\bigcdot)$, each of the simulated covariates enters the linear predictors of $x_{en}$ and $y$ directly. This formulation is used to investigate the performance of IV-DR methods in cases where the underlying functional forms happen to be linear. 
%
%Equations (\ref{datageneration}) - (\ref{responsegeneration}) are denoted as the “Generation Step”. The synthetic data required for the simulation study is then generated using the following procedure: Run the Generation Step, then calculate the correlations: "instrument relevance" $\rho_1(f_d(x_{IV}), x_{en})$, and "degree of endogeneity" $\rho_2(f_d(x_{en}), f_d(x_{u}))$. If they lie within an arbitrary range, store the sampled variables as one data set. Otherwise discard the variables, and return to the "Generation Step". With this procedure an arbitrary amount $C$ of data sets consisting of mixtures of sample sizes and distributional combinations can be generated. On this collection of synthetic data sets, three different regression models are estimated. Their specifications are in listed in Table \ref{specmodels}.
%\begin{table}[ht]
%\centering
%\caption[Model specification in the simulation study.]{Specification of the models in the simulation study.}
%\begin{tabular}{crl}
%  \toprule
% Model & & Specification \\ 
%  \midrule
%  \rowcolor{LightCyan}
%2SLS & $\mu^{en} =$ &  $\mathbbm{1}\beta_0^{[1]} + \boldsymbol{x}_{IV}\boldsymbol{\beta}_{IV}^{[1]} + \boldsymbol{x}_{ex}\boldsymbol{\beta}_{ex}^{[1]}$ \\
%  & $\mu^{y} =$ &  $\mathbbm{1}\beta_{0}^{[2]} + \boldsymbol{x}_{ex}\boldsymbol{\beta}_{ex}^{[2]} + \boldsymbol{\hat{x}}_{en}\boldsymbol{\beta}_{en}^{[2]}$ \\
%\rowcolor{LightCyan}
%$\text{2SGAMLSS}$ & $\vartheta^{en}_{1} =$ &  $\mathbbm{1}\beta_0^{[1]} + \boldsymbol{Z}_{IV}\boldsymbol{\beta}_{IV}^{[1]} + \boldsymbol{Z}_{ex}\boldsymbol{\beta}_{ex}^{[1]}$ \\
% & $\vartheta^{y}_{k} =$ &  $\mathbbm{1}\beta_{k,0}^{[2]} + \boldsymbol{Z}_{k,ex}\boldsymbol{\beta}_{k,ex}^{[2]} + \boldsymbol{Z}_{k,en}\boldsymbol{\beta}_{k,en}^{[2]} + \boldsymbol{Z}_{k,\hat{\xi}}\boldsymbol{\beta}_{k,\hat{\xi}}^{[2]}$\\
% Benchmark & $\vartheta^{y}_{k} =$& $ \mathbbm{1}\beta_{k,0} + \boldsymbol{Z}_{k,ex}\boldsymbol{\beta}_{k,ex} + \boldsymbol{Z}_{k,en}\beta_{k,en} + \boldsymbol{Z}_{k,u}\boldsymbol{\beta}_{k,u}$\\
%   \bottomrule
%\end{tabular}
%\label{specmodels}
%\end{table}
%
%Where the superscripts [1], and [2] denote the first, and second steps of the IV methods. The design matrices $\boldsymbol{Z}_{\bigcdot}$ contain the basis functions evaluated at observations of the covariate $x_{\bigcdot}$. The Benchmark model performs a regression on all of the true components of the response distribution parameters. Both 2SLS \& 2SGAMLSS are estimated in their respective two-step fashion. The quality of the estimators is given by point-wise precision of the models' estimated coefficients. This is quantified using the Root Mean Square Error (RMSE) in relation to the Benchmark model, defined as: 
%\begin{equation}\label{ContRMSE}
%   \text{RMSE}(\hat{f}(x)) = \sqrt{\frac{1}{N}\displaystyle\sum_{i=1}^N\left[(\hat{f}^{Bench}(x_{en,i}) - \hat{f}(x_{en,i}))^2\right]} 
%\end{equation}
%where the superscript \textit{Bench} denotes the estimation carried out by the Benchmark model, and $\hat{f}(x_i)$ is the estimated non-linear function evaluation of $x_{en,i}$ using any of the remaining methods. In cases where $x_{en}$ is a binary variable (e.g. a treatment indicator), the RMSE is calculated using the following definition:
%\begin{equation}\label{DiscRMSE}
%   \text{RMSE}(\hat{\beta}) = \sqrt{\frac{1}{C}\displaystyle\sum_{c=1}^{C}\left[(\hat{\beta}_c^{Bench} - \hat{\beta}_c)^2\right]}
%\end{equation}
%The RMSE of Equation \ref{ContRMSE} is computed for each estimated non-linear component within each iteration $c = 1, \dots, C$. The second definition compares $\hat{\beta}$ to $\hat{\beta}^{Bench}$ using all $C$ iterations, resulting in only 1  RMSE point per case. The estimation of the endogenous treatment's effect is of primary interest in those scenarios. Lower values of the RMSE indicate a closer point-wise fit to the Benchmark model. 
%
%\par The bias incurred by each model is given by
%\begin{equation*}
%    \text{Bias}(\hat{f}(x_{en})) = \frac{1}{n}\sum_{i=1}^n \mathbb{E}(\hat{f}(x_{en,i})) - f(x_{en,i})
%\end{equation*}
%Yielding a total of $C$ measurements for the Bias. Average Bias across the $C$ Monte Carlo Replications will be documented.
%\begin{table}[ht]
%\caption[Definition of non-linear functions.]{Definition of the non-linear functions. All lie in the domain [0,1].}
%  \centering
%  \fontfamily{ppl}\selectfont
%  \begin{tabular}{ll}
%    \toprule
%    Function & Definition \\
%    \midrule
%    \rowcolor{LightCyan}
%    $f_1(x)$ & $\cos(2\pi x)$ \\
%    $f_2(x)$ & $0.5\{x^3+\sin(\pi x^3)\}$ \\
%    \rowcolor{LightCyan}
%    $f_3(x)$ & -$0.5\{x + \sin(\pi x^{2.5})\} $ \\
%    $f_4(x)$ & $\beta_{20,22}(x) - \beta_{4,10}(x) - \beta_{6,8}(x)$\\
%    \rowcolor{LightCyan}
%    $f_5(x)$ &  $x^{11}\{10(1-x)\}^6 + 10(10x)^3(1-x)^{10}$\\
%    $f_6(x)$ & $\sin(x)^5 + (x^2-2)^9+ 10$\\
%    \rowcolor{LightCyan}
%    $f_7(x)$ & $-\{6\beta_{18,12}(x) + 3\beta_{3,12}(x) + 5\beta_{3,12}(x)\}-1$\\
%    $f_8(x)$ & $-\{ 6\beta_{30,17}(x)/10 + 4\beta_{3,11}(x)/10\}$ \\
%    \rowcolor{LightCyan}
%    $f_{9}(x)$ & $\{3\beta_{3,13}(x) + \beta_{8,8}(x) + \beta_{25,5}(x)\}-1$\\
%    $f_{10}(x)$ & $\sin(\pi x)$\\
%    \rowcolor{LightCyan}
%    $\beta_{l,m}(x)$ & $\{\Gamma (l + m) / \Gamma (l)\Gamma (m)\}x^{l-1}(1-x)^{m-1} $\\
%    \bottomrule
%  \end{tabular}
%  \label{functions}
%\end{table}
%
%\pagebreak
%\subsection{Confidence Intervals}
%The ($1 - \alpha$) confidence intervals are an important precision indicator of any statistical estimator. Since 2SGAMLSS relies on a two step estimation, a \textit{straight-forward} calculation results in intervals that do not necessarily cover their claimed nominal probability, i.e. they will be too narrow. This is due to the fact that the second-stage estimation does not take into account the uncertainty from the quantities estimated in the first-stage regression. In order to reliably represent the uncertainty of the estimated parameters, an additional correction must be considered if poor coverage probabilities are to be avoided. 
%\par Predecessors of 2SGAMLSS have employed a bootstrap point-wise confidence interval correction to return the estimated intervals to their nominal coverage probabilities. The algorithm originally proposed by \cite{FlexibleIVApproach}, and later adapted to an expectile regression setting by \cite{sobotka2013estimating} is brought into the Distributional Regression framework. The low coverage probabilities are rectified by employing the joint asymptotic distribution of the GAMLSS Maximum Likelihood estimators \citep{FlexRegGAMLSS}:
%\begin{equation*}
%    f_{\theta}(\boldsymbol{\hat{\theta}}|\boldsymbol{y}, \lambda, \hat{\sigma}^2)\sim\mathcal{N}(\boldsymbol{\theta},\boldsymbol{\Sigma}_{\theta})
%\end{equation*}
%Where $\boldsymbol{\hat{\theta}}$ is the Maximum Likelihood estimate of the parameter vector $\boldsymbol{\theta}$ obtained via the \li{R} routine \li{GJRM::gamlss()}. These estimates are of the form $(\boldsymbol{X}'\boldsymbol{W}\boldsymbol{X}+\boldsymbol{P})^{-1}\boldsymbol{X}'\boldsymbol{W}\boldsymbol{z}$. The estimator follows asymptotically a Gaussian distribution centered around the true value and its covariance matrix is given by the parameters':  $\boldsymbol{\Sigma}_{\theta} = (\boldsymbol{X}'\boldsymbol{W}\boldsymbol{X}+\boldsymbol{P})^{-1}\hat{\sigma}^2$. Where the empirical estimator of the residual variance is given by: $\hat{\sigma}^2 = \sum(y_i - \hat{y}_i)^2/(1-diag(\boldsymbol{H}))$. The modified algorithm for obtaining valid confidence intervals is the following \citep{FlexibleIVApproach}:
%\begin{itemize}
%    \item Estimate the first-stage model. Draw a total of $N_b$ random vectors from a multivariate Gaussian distribution: $\mathcal{N}(\boldsymbol{{\hat{\beta}}}^{[1]}, \boldsymbol{\hat{\Sigma}}^{[1]})$. Calculate all $N_b$ vectors of predicted values $\boldsymbol{\hat{x}}^*_{en,1}, \dots, \boldsymbol{\hat{x}}^*_{en,N_b}$, and their respective residuals $\boldsymbol{\hat{\xi}}^*_{1}, \dots, \boldsymbol{\hat{\xi}}^*_{N_b}$.
%    \item Fit the second-stage models $N_b$ times using the original data attaching the $N_b$-th vector of residuals. Obtain $\boldsymbol{\hat{\beta}}^{[2]}$ and $\boldsymbol{\hat{\Sigma}}^{[2]}$.
%    \item For each $n_b =1, \dots, N_b$ draw $N_d$ random vectors from a multivariate Gaussian distribution: $\mathcal{N}(\boldsymbol{{\hat{\beta}}}^{[2]}, \boldsymbol{\hat{\Sigma}}^{[2]})$.
%    \item Calculate the $N_b N_d$ fitted values, and compute the point-wise bootstrap percentile intervals.
%\end{itemize}
%Using this procedure the uncertainty of the residuals $\hat{\xi}$ is accounted for in each of the estimated distribution parameters. This procedure should restore the coverage probabilities of the confidence intervals. The original suggestions are considered for this variant: $N_b$ = 25, and $N_d$ = 100. 
%\pagebreak
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%% ----------------------------------
%%%%%%%%%%%%% ---------------------------------------------------
%%%%%%%% C O M M O N    P A R A M E T E R    S E T T I N G S %%%%%%
%%%%%%%%%%%%% ---------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%% ---------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Simulation Parameter Settings}
%In order to achieve exact replicability of the entire simulation study, this subsection is dedicated to the documentation of the common parameter settings. The case of endogeneity due to unmeasured confounders is studied considering only a \textit{strong} instrument $x_{IV}$. The strength of $x_{IV}$ is defined by $|\rho_1(x_{en}, f_d(x_{IV}))|>0.4$. The effect of the strong instrument is then investigated under a \textit{severe} endogeneity, defined by $|\rho_{2}(f_d(x_{u}), f_d(x_{en}))|>0.5$. Given these settings, three different types of endogeneity can be distinguished: "Continuous" and "Parametric" Endogeneity. These premises yield a total of eight distributional combinations that will be investigated across 3 different sample sizes: $N = 500, 2000, 4000$. Using the data-generating algorithm, a total of $C = 1000$ independent data sets are generated for each sample size and case. The studied combinations of distributions of $x_{en}$ and $y$ are formulated with the intention of studying typically encountered response distributions. Table \ref{DistCombis} shows the studied distributions, as well as the generated parameter vectors $\boldsymbol{\theta}$. The specifications of the distribution parameters' predictors, including both the endogenous and response variables, are displayed in Table \ref{AllSpecs}. 
%\begin{table}[h!]
%\center
%\caption[Studied distributional combinations.]{Types of endogeneity, and distributional combinations of $x_{en}$ \& $y$ with their respective parameter vector $\boldsymbol{\theta}=(\mu, \sigma, \nu, \tau)$.}
%\begin{tabular}{ccllll}
% \toprule
%Case & Type &$x_{en}$ & $\boldsymbol{\theta}^{en}$ & $y$ & $\boldsymbol{\theta}^y$\\ 
%  \midrule
%  \rowcolor{LightCyan}
%1& Continuous &Gaussian & $\mu$  & Gaussian & $\mu$, $\sigma$ \\ 
%2& &Gaussian &  $\mu$   & Binomial & $\mu$ \\
%\rowcolor{LightCyan}
%3& &Gaussian &  $\mu$  & Negative Binomial & $\mu$, $\sigma$ \\ 
%4& &Gaussian &  $\mu$  & Gamma & $\mu$, $\sigma$\\
%\rowcolor{LightCyan}
%5& Parametric & Binomial &  $\mu$ & Gaussian &  $\mu$, $\sigma$\\ 
%6& &Binomial & $\mu$ & Binomial & $\mu$ \\
%\rowcolor{LightCyan}
%7& &Binomial & $\mu$ & Negative Binomial & $\mu$, $\sigma$\\
%8& &Binomial & $\mu$ & Gamma & $\mu$, $\sigma$\\
%   \bottomrule
%\end{tabular}
%\label{DistCombis}
%\end{table}
%
%The non-linear functions $f_d(\bigcdot)$ are estimated in all models using P-Splines. The functions are approximated using a B-Spline basis on $q = 20$ equidistant knots, and cubic polynomials (degree $l = 3$). The GAMLSS models are estimated using a trust-region algorithm \citep{gjrm}. Replicability of the simulation is guaranteed using a pre-specified set of seeds to initialize the pseudo-random number generator. The point-wise precision simulation study consists of: $3$ sample sizes $\times$ $8$ combinations $\times$ $1000$ data sets $= 24000$ data sets.
%
%
%\par The Confidence Intervals are studied using a simplified simulation. The coverage probabilities of the 2SGAMLSS's intervals is investigated using the Gaussian $\sim$ Gaussian combination. The intervals are obtained using the bootstrap procedure outlined in Section 1.2. The coverage probabilities are computed for both the \li{terms} (covariate predictions) and $\mathbb{E}(Y)$ (response's expectation prediction). The simulation study of the Confidence Intervals will be carried out using $C=500$ independent samples of size $N=2000$ (suggestions?).  
%\pagestyle{empty}
%\begin{sidewaystable}[h!]
%\centering
%\caption[Definition of studied distributions.]{Specifications of the distributions employed in the simulation study. }
%\scalebox{.93}{
%\begin{tabular}{llllcl}
%  \toprule
%   Endogenous & & & & & \\
%Distribution  & Density & Range & Parameters &  Link function & Predictor \\ 
%\midrule
%\rowcolor{LightCyan}
%Gaussian  & $f_{en}(x_{en}|\text{ }\mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma}} \text{exp}(-\frac{(x_{en}-\mu)^2}{2\sigma^2})$ & $x_{en,i} \in \mathbb{R}$ & $\mu^{en} \in \mathbb{R}$  & $identity$ & $\eta^{en}_1 = f_2(x_{u}) + f_4(x_{IV}) $\\ 
%\midrule
%Binomial & $P_{en}(X_{en}=x_{en}|\text{ }\mu, n) = \binom{n}{x_{en}} \mu^{x_{en}}(1-\mu)^{n-x_{en}}$ & $x_{en,i} \in [0,1]$ & $\mu^{en} \in [0,1]$  & $logit$ & $\eta^{en}_1 = f_2(x_{u}) + f_4(x_{IV})$ \\ 
%\midrule
% Response & & & & & \\
%Distribution  & Density & Range & Parameters &  Link function & Predictor \\ 
%  \midrule
%  \rowcolor{LightCyan}
%Gaussian  & $f_y(y|\text{ }\mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma}} \text{exp}(-\frac{(y-\mu)^2}{2\sigma^2})$ & $y_i \in \mathbb{R}$ & $\mu^{y} \in \mathbb{R}$  & $identity$ & $\eta^{y}_1 = f_1(x_{ex_1}) + f_5(x_{en}) +f_3(x_u)$ \\ 
%\rowcolor{LightCyan}
%$y_i\sim\mathcal{N}(\mu, \sigma)$                                       &         &                    & $\sigma^{y} \in \mathbb{R}_+$ & $log$ & $\eta^{y}_2 = f_{11}(x_{ex_2}) + f_6(x_{en}) + f_7(x_{u})$  \\
%       \midrule
% Binomial & $P_y(Y = y|\text{ }\mu,n) = \binom{n}{y} \mu^y(1-\mu)^{n-y}$ & $y_i \in [0,1]$ & $\mu^{y} \in [0,1]$  & $logit$ & $\eta^{y}_1 = f_1(x_{ex}) + f_5(x_{en}) +f_3(x_u)$ \\ 
% $y_i\sim\mathcal{B}(\mu,1)$ & & & &   & \\
% \midrule
% \rowcolor{LightCyan}
% Gamma &  $f_{y}(y|\mu,\sigma) = \frac{\exp-(y/\sigma)y^{(\mu-1)}}{(\sigma^\mu \Gamma(\mu))}$ & $y_i \in \mathbb{R}_+$ & $\mu^{y} \in \mathbb{R}_+$ & $log$ &  $\eta^{y}_1 = f_1(x_{ex_1}) + f_5(x_{en}) +f_3(x_u)$\\ 
% \rowcolor{LightCyan}
% $y_i\sim\mathcal{G}(\mu,\sigma)$   &    &             & $\sigma^{y} \in \mathbb{R}_+$ & $log$ & $\eta^{y}_2 = f_{11}(x_{ex_2}) + f_6(x_{en}) + f_7(x_{u})$  \\
%        \midrule
%Negative Binomial & $P_y(Y = y | \text{ }\mu,\sigma) = \frac{\Gamma(y+\frac{1}{\sigma})}{\Gamma(\frac{1}{\sigma})\Gamma(y+1)}\left( \frac{\sigma \mu}{1+\sigma\mu}\right)^y \left(\frac{1}{1+\sigma\mu} \right)^{\frac{1}{\sigma}}$ & $y_i \in \mathbb{R}_+$ & $\mu^{y} \in \mathbb{R}_+$ & $log$ & $\eta^{y}_1=f_1(x_{ex_1}) + f_5(x_{en}) +f_3(x_u)$\\
%$y_i\sim\mathcal{NB}(\mu,\sigma,\nu)$         &            &                    & $\sigma^{y} \in \mathbb{R}_+$ & $log$ & $\eta^{y}_2 = f_{11}(x_{ex_2}) + f_6(x_{en}) + f_7(x_{u})$  \\
%   \bottomrule
%\end{tabular}
%}
%\label{AllSpecs}
%\end{sidewaystable}
%


%%%%---------------------------------------------------------------------------------
%%%%------------------- S E C T I O N     N O M E N C L A T U R E -------------------

%%% V A R I A B L E S

\nomenclature[C, 04]{$\boldsymbol{y}$}{Response vector.}
\nomenclature[C, 05]{$y$}{Response variable.}
\nomenclature[C, 01]{$\boldsymbol{X}$}{Design matrix of discrete explanatory variables.}
\nomenclature[C, 02]{$\boldsymbol{Z}$}{Design matrix of a continuous explanatory variable.}
\nomenclature[C, 06]{$x_{ex}$}{Exogenous regressor.}
\nomenclature[C, 07]{$x_{en}$}{Endogenous regressor.}
\nomenclature[C, 08]{$x_{IV}$}{Instrumental variable.}
\nomenclature[C, 09]{$x_{u}$}{Unobservable regressor.}
\nomenclature[C, 03]{$\boldsymbol{P}$}{Penalty matrix.}
%\nomenclature[C, 08]{$z_{\bigcdot}$}{Continuous explanatory variable.}


%%% S E T S  &  I N D I C E S 
\nomenclature[A, 02]{$K$}{Set of response distribution parameters: $k = 1,\dots,K$.}
\nomenclature[A, 03]{$M$}{Set of endogenous variable distribution parameters: $m = 1,\dots,M$.}
\nomenclature[A, 01]{$I$}{Set of observations: $i = 1, \dots,n$.}
\nomenclature[A, 04]{$D$}{Set of continuous functions: $d = 1,\dots,D$.}
\nomenclature[A, 07]{$N$}{Sample size.}
\nomenclature[A, 08]{$C$}{Number of Monte Carlo replications: $c = 1, \dots, C$.}
\nomenclature[A, 05]{$J$}{Set of explanatory variables: $j = 1, \dots, J$.}
\nomenclature[A, 06]{$R$}{Set of first-stage regression explanatory variables: $r = 1, \dots, J-1 +$ instrument.}
%% DISTRIBUTIONS
\nomenclature[B]{$\mathcal{U}$}{Uniform distribution with support $[a,b]$.}
\nomenclature[B]{$\mathcal{B}$}{Binomial distribution with parameter $\mu$.}
\nomenclature[B]{$\mathcal{N}$}{Normal distribution with parameters $\mu$, and $\sigma$.}
\nomenclature[B]{$\mathcal{G}$}{Gamma distribution with parameters $\mu$, and $\sigma$.}
\nomenclature[B]{$\mathcal{D}$}{Dagum distribution with parameters $\mu$, $\sigma$, and $\nu$.}

%%%%%%%%%%%%%%
% O T H E R    S Y M B O L S %%%%%%%%%%% 
\nomenclature[E, 02]{$\eta_{\bigcdot}^{\bigcdot}$}{Additive predictor of the $k$-th, or $m$-th distribution parameter.}
\nomenclature[E, 01]{$\boldsymbol{\theta}_{\bigcdot}$}{Vector of $K$ or $M$ distribution parameters:  $\boldsymbol{\theta} = (\mu, \sigma, \nu, \tau)$.  }
\nomenclature[E, 03]{$\vartheta^{y}_{k}$}{$k$-th distribution parameter of the response.}
\nomenclature[E, 04]{$\vartheta^{en}_{m}$}{$m$-th distribution parameter of the endogenous regressor.}
\nomenclature[E, 05]{$\beta_{\bigcdot}$}{Regression coefficient.}
\nomenclature[E, 06]{$\hat{\beta}_{\bigcdot}$}{Estimates of the regression coefficient $\beta$.}
\nomenclature[E, 07]{$\phi$}{Simulation control parameter.}
\nomenclature[E, 08]{$\gamma$}{Penalized smoother coefficient.}
\nomenclature[E, 09]{$\lambda$}{Smoothing parameter. }

%%%%%%%%%%%%%
%% F U N C T I O N S
\nomenclature[D, 04]{$\hat{f}(\bigcdot)$}{Estimated function of a continuous covariate.}
\nomenclature[D, 01]{$f_y(\bigcdot)$}{Response distribution function.} 
\nomenclature[D, 02]{$f_{en}(\bigcdot)$}{Distribution function of the endogenous regressor.}
\nomenclature[D, 03]{$f_d(\bigcdot)$}{The $d$-th continuous function.}
\nomenclature[D, 05]{$g_{\bigcdot}(\bigcdot)$}{$m$-th or $k$-th link function of the $m$-th or $k$-th distribution parameter.}
\nomenclature[D, 06]{$h_{\bigcdot}(\bigcdot)$}{$m$-th or $k$-th response function of the $m$-th or $k$-th distribution parameter.}
\nomenclature[D, 07]{$\ell(\bigcdot)$}{Log-likelihood function.}
\nomenclature[D, 08]{$\ell_p(\bigcdot)$}{Penalized log-likelihood function.}


%%%%---------------------------------------------------------------------------------
%%%%------------------- S E C T I O N     N O M E N C L A T U R E -------------------
\nomenclature[F, 07]{2SDR}{Two-Stage Distributional Regression.}

\pagebreak
%\section*{References}
%\addcontentsline{toc}{section}{References}
\rhead{References}
\bibliography{biblio}

\end{document}
